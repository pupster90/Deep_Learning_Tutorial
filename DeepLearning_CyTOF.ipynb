{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=6>Diagnose latent Cytomegalovirus using Deep learning</font></center>\n",
    ".\n",
    "\n",
    "<center>Zicheng Hu, Ph.D.</center>\n",
    "<center>The Unversity of California, San Francisco</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will achieve the following goals:\n",
    "1. Learn how to use **keras**, a popular deep learning framework.\n",
    "1. Construct a deep learning model tailered to cytometry data. \n",
    "1. Apply the deep learning model to diagnose latent cytomegalovirus (CMV) infection. \n",
    "1. Examine and interpret the internal layers of the deep learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this tutorial has to be downloaded. We check to see if the dataset has already been downloaded, and if not we download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_files = ! ls\n",
    "if \"allData.obj\" not in tutorial_files:\n",
    "    print(\"Downloading Data:\")\n",
    "    ! wget https://storage.googleapis.com/public-files-900/Zicheng_Tutorial/allData.obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we first import libraries that we will use in this tutorial, including:\n",
    "* **keras**, a library the handles the user-end of deep learning. \n",
    "* **tensorflow**, a library that handles the back-end of deep learning.\n",
    "* **pickle**, a library for loading data.\n",
    "* **pandas**, a library for manipulating data. \n",
    "* **random**, a library for generating random numbers. \n",
    "* **numpy**, a library for matrix computation. \n",
    "* **matplotlib**, a library for data visualization\n",
    "* **sklearn**, a library that provides infranstructure of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import functions #####\n",
    "from __future__ import print_function\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.python.keras.layers import Conv2D, AveragePooling2D, Input\n",
    "from tensorflow.python.keras.models import load_model, Model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.python.keras import backend as K\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed; seed(111)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data, which are stored in the \"allData.obj\" file. For the convinience of this tutorial, the data are downloaded from the ImmPort database and are already preprocessed. The data includes three parts, meta-data, CyTOF data and marker names. \n",
    "* The meta-data contains the demographic information of each subject, the study acession number for each sample, and the ground truth of CMV infection. It is stored as a pandas data frame. \n",
    "* The CyTOF data contains the single-cell profile of 27 markers. It is stored in a three-dimentional numpy array. The dimension of the numpy array is : 472 samples x 10000 cells x 27 markers. \n",
    "* The marker names contains the name of the 27 makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load data #####\n",
    "allData = pickle.load( open( \"allData.obj\", \"rb\" ) )\n",
    "metaData = allData[\"metaData\"]\n",
    "cytoData = allData[\"cytoData\"]\n",
    "markerNames = allData[\"markerNames\"]\n",
    "print(\"Dimension of cytoData: \",cytoData.shape)\n",
    "print(\"Names of the 27 makers: \\n\",markerNames.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into training, validation and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets split the data into training, validation and testing sets. The training data is used to train the deep learning model. The validation dataset is used to select the best parameters for the model and to avoid overfitting. The test dataset is used to evaluate the performance of the deep learning model.\n",
    "\n",
    "We will use samples from the study SDY515 as validation set, samples from the study SDY519 as testing set, and the rest samples as training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### split train, validation and test######\n",
    "y = metaData.CMV_Ab.values\n",
    "x = cytoData\n",
    "\n",
    "train_id = (metaData.study_accession.isin([\"SDY515\",\"SDY519\"])==False)\n",
    "valid_id = metaData.study_accession==\"SDY515\"\n",
    "test_id = metaData.study_accession ==\"SDY519\"\n",
    "\n",
    "x_train = x[train_id]; y_train = y[train_id]\n",
    "x_valid = x[valid_id]; y_valid = y[valid_id]\n",
    "x_test = x[test_id]; y_test = y[test_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define deep learing model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a customized convolution neural network (CNN) to analyze the CyTOF data. For each sample, the CyTOF data is a matrix with rows as cells and columns as markers. It is important to notice that the order of cells is arbitry in CyTOF data. For example, both matrix 1 and matrix 2 profiles the sample sample in Figure 1. \n",
    "\n",
    "Based on the characterisitics of the CyTOF data, we can design a CNN model that use the raw cytof data as input, without the need of cell gating or cell clustering. The model contains 6 layers: input layer, first and second convolution layer, pooling layer, dense layer, and output layer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input layer\n",
    "model_input = Input(shape=x_train[0].shape)\n",
    "\n",
    "# first convolution layer\n",
    "model_output = Conv2D(3, kernel_size=(1, x_train.shape[2]),\n",
    "                 activation=None)(model_input)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# sceond convolution layer\n",
    "model_output = Conv2D(3, (1, 1), activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# pooling layer\n",
    "model_output = AveragePooling2D(pool_size=(x_train.shape[1], 1))(model_output)\n",
    "model_output = Flatten()(model_output)\n",
    "\n",
    "# Dense layer\n",
    "model_output = Dense(3, activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "# output layer\n",
    "model_output = Dense(1, activation=None)(model_output)\n",
    "model_output = BatchNormalization()(model_output)\n",
    "model_output = Activation(\"sigmoid\")(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs=[model_input],\n",
    "              outputs=model_output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_weights.hdf5', \n",
    "                               monitor='val_loss', verbose=0, \n",
    "                               save_best_only=True, save_weights_only = True)\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='loss', min_delta=0.00000001, \n",
    "                          patience=100, verbose=0, mode='auto', \n",
    "                          baseline=None, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit([x_train], y_train,\n",
    "          batch_size=60,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks= [checkpointer, earlyStop], #[checkpointer, earlyStop], \n",
    "          validation_data=([x_valid], y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### test the final model #####\n",
    "best_model = load_model('Final_weights.hdf5')\n",
    "y_scores = best_model.predict([x_test])\n",
    "test_auc = roc_auc_score(y_true=y_test, y_score=y_scores)\n",
    "print('The Area Under the Curve (AUC) = {0:.2f}'.format(test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### get activation value #####\n",
    "get_6th_layer_output = K.function([best_model.layers[0].input],\n",
    "                                  [best_model.layers[6].output])\n",
    "sixth_layer_output = get_6th_layer_output([x_test])[0]\n",
    "\n",
    "plot_df = x_test.reshape((x_test.shape[0]*x_test.shape[1],\n",
    "                          x_test.shape[2]))\n",
    "plot_df = pd.DataFrame(plot_df,columns=markerNames)\n",
    "\n",
    "activation = sixth_layer_output[:,:,:,0]\n",
    "plot_df[\"activation\"] = (activation.reshape((activation.shape[0]*activation.shape[1],\n",
    "                          activation.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "plot_df2 = plot_df.sample(10000)\n",
    "\n",
    "sns.scatterplot(x=plot_df2[\"CD8\"], y=plot_df2[\"CD3\"], \n",
    "                hue=(plot_df2[\"activation\"]>0.5),s = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
